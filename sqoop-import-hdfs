# To list all databases, run:
sqoop list-databases --connect jdbc:mysql://localhost --username root --password ****

# To list all tables, run:
sqoop list-tables --connect jdbc:mysql://localhost/retail_db --username root --password ****

# To run SQL Query from sqoop, run:
sqoop eval --connect jdbc:mysql://localhost/retail_db --username root --password **** --query "select * from orders limit 10"

# To import data from MySQL to HDFS, run
sqoop import --connect jdbc:mysql://localhost/retail_db --username root --password *** \
  --table order_items --target-dir /user/cloudera/sqoop-import/retail_db/order_items
 
# To delete the target dir if already exist before importing the table, type:
sqoop import --connect jdbc:mysql://localhost/retail_db \
 --username root --password cloudera \
--table order_items \
--target-dir /user/cloudera/sqoop-import/retail_db/order_items \
--delete-target-dir

# To append to an existing target dir, type:
sqoop import --connect jdbc:mysql://localhost/retail_db \
 --username root --password cloudera \
--table order_items \
--target-dir /user/cloudera/sqoop-import/retail_db/order_items \
--append

# To import data where there's not primary key column defined, you'll have to split by another column, type:
sqoop import \
  --connect jdbc:mysql://example.cluster.com:3306/retail_db \
  --username root \
  --password **** \
  --table order_items_nopk \
  --warehouse-dir /user/cloudera/sqoop_import/retail_db \
  --split-by order_item_order_id
  
 
#Splitting on text field
sqoop import \
  -Dorg.apache.sqoop.splitter.allow_text_splitter=true \
  --connect jdbc:mysql://example.cluster.com:3306/retail_db \
  --username retail_user \
  --password **** \
  --table orders \
  --warehouse-dir /user/cloudera/sqoop_import/retail_db \
  --split-by order_status
  

# Another way to import a table that doesn't have a primary key is as below:
sqoop import --connect jdbc:mysql://localhost/retail_db --username root --password **** \
  --table orders --warehouse-dir /user/cloudera/sqoop-import/retail_db --autoreset-to-one-mapper
  
# To import to HDFS in a specific format, run:
sqoop import --connect jdbc:mysql://localhost/retail_db --username root --password **** \
  --table order_items --target-dir /user/cloudera/sqoop-import/retail_db/order_items \
  --append --as-textfile or --as-avrodatafile or as-parquetfile or --as-sequencefile
  
 # To import data with compression, first you'll have to know the compression codecs installed on the cluster, run the below command
 # to know how to get them
 vi /etc/hadoop/conf/core-site.xml
 # then seach for /codec and you'll see the list of compression codecs installed
 org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec,
 org.apache.hadoop.io.compress.DeflateCodec,org.apache.hadoop.io.compress.SnappyCodec,org.apache.hadoop.io.compress.Lz4Codec
 
 # then run the below sqoop import command
 sqoop import --connect jdbc:mysql://localhost/retail_db --username root --password **** \
   --order_items --warehouse-dir /user/cloudera/sqoop-import/retail_db \
   --as-textfile --num-mappers 2 \
   --compress --compression-codec org.apache.hadoop.io.compress.GzipCodec
   
 # To import certain columns from a table, run
 sqoop import --connect jdbc:mysql://localhost/retail_db --username root --password **** \
  --table order_items --columns order_item_order_id,order_item_id,order_item_subtotal \
  --target-dir /user/cloudera/sqoop-import/retail_db/order_items \
  --num-mappers 2
  

# To import data using query, run
sqoop import --connect jdbc:mysql://localhost/retail_db --username root --password **** \
  --target-dir /user/cloudera/sqoop-import/retail_db/order_items --num-mappers 2 \
  --query "select o.*, sum(oi.order_item_subtotal) order_revenue from orders o join order_items oi on o.order_id = oi.order_item_order_id and \$CONDITIONS group by o.order_id, o.order_date, o.order_customer_id, o.order_status" \
  --split-by order_id
  
 
# Or run below to import only order_date of year 2013
sqoop import --connect jdbc:mysql://localhost/retail_db --username root --password cloudera \
  --target-dir /user/cloudera/sqoop-import/retail_db/order_items --num-mappers 2 \
  --query "select * from orders where \$CONDITIONS and order_date like '2013-%'" \
  --split-by order_id
 
# Import data using where condition
sqoop import --connect jdbc:mysql://localhost/retail_db --username root --password cloudera \
  --target-dir /user/cloudera/sqoop-import/retail_db/order_items --num-mappers 2 \
  --query "select * from orders where \$CONDITIONS and order_date like '2014-01%'" \
  --split-by order_id --append
  
  
# You can also use table in conjunction with where condition as below:
sqoop import --connect jdbc:mysql://localhost/retail_db --username root --password cloudera \
  --target-dir /user/cloudera/sqoop-import/retail_db/order_items --append --num-mappers 2 \
  --table orders --where "order_date like '2014-02%'"
  

# Incremental load using sqoop arguments itself without any where condition
sqoop import --connect jdbc:mysql://localhost/retail_db --username root --password cloudera \
  --target-dir /user/cloudera/sqoop-import/retail_db/order_items --num-mappers 2 \
  --table orders \
  --check-column order_date \
  --incremental append \
  --last-value '2014-02-28'


# To import all tables from MySQL to HDFS, run the below, note that you've to use --warehouse-dir flag when importing all tables
sqoop import-all-tables --connect jdbc:mysql://localhost/retail_db --username root --password *** \
  --warehouse-dir /user/cloudera/sqoop-import/retail_db/order_items \
  --autoreset-to-one-mapper
  
  
  
  

  
  
  
